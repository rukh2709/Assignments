{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6178f6e-be1b-438e-b0b3-015538a1848c",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e969b-e1ac-4450-82e2-b90eb9f9cac9",
   "metadata": {},
   "source": [
    "Answer 1: Web scraping is the process of extracting data from websites automatically using software tools or algorithms. It involves collecting information from web pages, analyzing the data, and transforming it into a structured format for further use.\n",
    "\n",
    "Web scraping is used to gather large amounts of data from various websites quickly and efficiently. \n",
    "Some of the common reasons for using web scraping include:\n",
    "Market Research\n",
    "Content Aggregation\n",
    "Data Mining\n",
    "\n",
    "Here are three specific areas where web scraping is commonly used to collect data:\n",
    "(1) E-commerce \n",
    "(2) Social Media\n",
    "(3) Real Estate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8fddb-49d0-4656-87e7-69a9769eef6b",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b80c2-d6a5-4f4e-a1af-db6a7ce94655",
   "metadata": {},
   "source": [
    "Answer 2: There are several methods used for web scraping, here are some of the most common methods used for web scraping:\n",
    "(a) Manual Web Scraping\n",
    "(b) Regular Expressions\n",
    "(c) HTML Parsing\n",
    "(c) Web Scraping Libraries\n",
    "(d) API-based Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360dfba-24ba-411e-9872-8ebd42228608",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04190f66-d88b-4100-87ce-8851a3cabbca",
   "metadata": {},
   "source": [
    "Answer 3: Beautiful Soup is a Python library that is used for web scraping purposes. It allows developers to parse HTML and XML documents and extract data from them in a structured way. Beautiful Soup is particularly useful when dealing with messy HTML or XML code, as it can handle poorly-formed or nested code and still extract the relevant data.\n",
    "\n",
    "Here are some of the reasons why Beautiful Soup is a popular choice for web scraping:\n",
    "(a) Easy to Use\n",
    "(b) Powerful Parsing Capabilities\n",
    "(c) Support for Popular Python Libraries\n",
    "(d) Extensive Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0becd457-5456-4793-a3d0-2a6634337565",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488425c0-13e3-4cc4-a549-b149188f8bb5",
   "metadata": {},
   "source": [
    "Answer 4: Flask is a Python web framework that is often used for developing web applications and APIs. Flask is lightweight and flexible, making it a popular choice for projects of all sizes. Flask is also well-suited for web scraping projects, as it allows developers to easily create web-based interfaces for scraping data and presenting it in a user-friendly way.\n",
    "\n",
    "following are some of the reasons why Flask is used in a web scraping project:\n",
    "(1) Web-Based Interface: Flask allows developers to create a web-based interface for their web scraping project.\n",
    "(2) Flask can be easily integrated with other Python libraries, including Beautiful Soup and requests.\n",
    "(3) Flask is designed to be flexible and scalable.\n",
    "(4) Flask applications can be easily deployed to a variety of platforms, including cloud-based hosting services such as Heroku or AWS. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6aabaa-dfdb-447e-bbcf-86ae246cb0dc",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f05f69-578e-405e-85a7-1a044f285ce1",
   "metadata": {},
   "source": [
    "Answer 5: CodePipeline and Elastic Beanstalk are the services of AWS which are used in a web scraping project.\n",
    "Explanation: Using CodePipeline, we create a pipeline that uses GitHub, Amazon S3, or AWS CodeCommit as the source location for application code and then deploys the code to an Amazon EC2 instance managed by AWS Elastic Beanstalk. Our pipeline will automatically deploy our code every time there is a code change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
